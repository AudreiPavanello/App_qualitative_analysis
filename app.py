import streamlit as st
import pandas as pd
from transformers import pipeline
import plotly.express as px
from collections import Counter
import re
import string
import io # Para exportar Excel

# --- Configura√ß√£o da P√°gina e Cache ---

st.set_page_config(page_title="An√°lise de Sentimentos PT-BR", layout="wide")

# Cache para carregar o modelo apenas uma vez
@st.cache_resource
def load_model():
    """Carrega o modelo de an√°lise de sentimentos."""
    try:
        model_name = "lxyuan/distilbert-base-multilingual-cased-sentiments-student"
        sentiment_pipeline = pipeline("text-classification", model=model_name)
        return sentiment_pipeline
    except Exception as e:
        st.error(f"Erro ao carregar o modelo: {e}")
        st.stop() # Interrompe a execu√ß√£o se o modelo n√£o carregar

# Cache para carregar e processar dados (evita reprocessar se o arquivo n√£o mudar)
# Usamos um hash do conte√∫do do arquivo como parte da chave de cache
@st.cache_data
def load_data(uploaded_file):
    """Carrega dados de um arquivo .csv ou .xlsx."""
    try:
        if uploaded_file.name.endswith('.csv'):
            df = pd.read_csv(uploaded_file)
        elif uploaded_file.name.endswith('.xlsx'):
            df = pd.read_excel(uploaded_file)
        else:
            st.error("Formato de arquivo n√£o suportado. Use .csv ou .xlsx")
            return None
        # Limpeza b√°sica: remove linhas onde todas as colunas s√£o NaN
        df.dropna(axis=0, how='all', inplace=True)
        return df
    except Exception as e:
        st.error(f"Erro ao ler o arquivo: {e}")
        return None

# --- Fun√ß√µes Auxiliares ---

def clean_text(text):
    """Limpa o texto: min√∫sculas, remove pontua√ß√£o, n√∫meros e espa√ßos extras."""
    if not isinstance(text, str):
        return "" # Retorna string vazia se n√£o for texto
    text = text.lower()
    text = re.sub(r'\d+', '', text) # Remove n√∫meros
    text = text.translate(str.maketrans('', '', string.punctuation)) # Remove pontua√ß√£o
    text = text.strip() # Remove espa√ßos no in√≠cio/fim
    text = re.sub(r'\s+', ' ', text) # Substitui m√∫ltiplos espa√ßos por um √∫nico
    return text

def get_word_counts(texts, sentiment_label, stop_words, n_top_words=20):
    """Conta as palavras mais frequentes para um determinado sentimento, excluindo stop words."""
    all_text = ' '.join([clean_text(text) for text in texts if isinstance(text, str)])
    words = all_text.split()

    # Remove stop words
    words = [word for word in words if word not in stop_words and len(word) > 2] # Ignora palavras curtas

    if not words:
        return pd.DataFrame(columns=['Palavra', 'Frequ√™ncia'])

    word_counts = Counter(words)
    most_common = word_counts.most_common(n_top_words)

    df_counts = pd.DataFrame(most_common, columns=['Palavra', 'Frequ√™ncia'])
    df_counts['Sentimento'] = sentiment_label # Adiciona coluna de sentimento para plotagem
    return df_counts

def analyze_sentiment(text, pipe):
    """Aplica o pipeline de sentimento de forma segura."""
    if pd.isna(text) or not isinstance(text, str) or text.strip() == "":
        return {"label": "N/A", "score": 0.0} # Retorna neutro/N/A para texto inv√°lido/vazio
    try:
        # O pipeline retorna uma lista, pegamos o primeiro elemento
        result = pipe(text)[0]
        # Mapear labels para portugu√™s (se necess√°rio e se o modelo n√£o o fizer)
        # O modelo lxyuan j√° retorna 'positive', 'negative', 'neutral'
        label_map = {'positive': 'Positivo', 'negative': 'Negativo', 'neutral': 'Neutro'}
        result['label_pt'] = label_map.get(result['label'], result['label']) # Usa o label original se n√£o mapeado
        return result
    except Exception as e:
        # st.warning(f"Erro ao analisar texto: '{text[:50]}...' ({e}). Marcando como N/A.")
        print(f"Erro ao analisar texto: '{text[:50]}...' ({e}). Marcando como N/A.") # Log no console
        return {"label": "Erro", "score": 0.0, "label_pt": "Erro"}

# Fun√ß√£o para gerar link de download de Excel (necess√°rio por causa do formato bin√°rio)
def to_excel(df):
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='AnaliseSentimento')
    processed_data = output.getvalue()
    return processed_data

# --- Interface do Streamlit ---

st.title("üìä Ferramenta de An√°lise de Sentimentos (PT-BR)")
st.markdown("""
Carregue um arquivo `.xlsx` ou `.csv` contendo uma coluna com textos (respostas, coment√°rios, etc.)
para realizar a an√°lise de sentimentos.
""")

# Carregar Pipeline (ser√° executado apenas uma vez)
sentiment_pipeline = load_model()

# --- Upload e Prepara√ß√£o dos Dados ---
uploaded_file = st.sidebar.file_uploader("1. Escolha o arquivo (.csv ou .xlsx)", type=['csv', 'xlsx'])

if uploaded_file:
    df_original = load_data(uploaded_file)

    if df_original is not None:
        st.sidebar.success(f"Arquivo '{uploaded_file.name}' carregado com sucesso!")
        st.subheader("Pr√©-visualiza√ß√£o dos Dados Originais")
        st.dataframe(df_original.head())

        # Sele√ß√£o da Coluna de Texto
        text_column = st.sidebar.selectbox(
            "2. Selecione a coluna com o texto para an√°lise",
            options=[''] + list(df_original.columns), # Adiciona op√ß√£o vazia
            index=0 # Come√ßa com a op√ß√£o vazia selecionada
        )

        if text_column:
            # Bot√£o para iniciar an√°lise
            if st.sidebar.button("üöÄ Iniciar An√°lise de Sentimentos", key="analyze_button"):
                if text_column not in df_original.columns:
                     st.error(f"Coluna '{text_column}' n√£o encontrada no arquivo.")
                else:
                    # Verifica se a coluna parece conter texto (heur√≠stica simples)
                    if not pd.api.types.is_string_dtype(df_original[text_column].dropna()):
                        st.warning(f"A coluna '{text_column}' n√£o parece ser do tipo texto. A an√°lise pode falhar ou gerar resultados inesperados.")

                    # Realiza a an√°lise
                    progress_bar = st.progress(0, text="Analisando textos...")
                    df_analysis = df_original.copy()
                    total_rows = len(df_analysis)
                    results = []

                    for i, text in enumerate(df_analysis[text_column]):
                        result = analyze_sentiment(text, sentiment_pipeline)
                        results.append(result)
                        # Atualiza a barra de progresso
                        progress_bar.progress((i + 1) / total_rows, text=f"Analisando textos... {i+1}/{total_rows}")

                    progress_bar.empty() # Limpa a barra de progresso

                    # Adiciona os resultados ao DataFrame
                    # Usar pd.json_normalize pode ser mais robusto se a estrutura do dict mudar
                    df_results = pd.DataFrame(results)
                    df_analysis['Sentimento_Label'] = df_results['label_pt']
                    df_analysis['Sentimento_Score'] = df_results['score'].round(4) # Arredonda score

                    # Armazena no estado da sess√£o para persistir
                    st.session_state['df_analyzed'] = df_analysis
                    st.session_state['text_column'] = text_column # Guarda a coluna analisada
                    st.success("An√°lise conclu√≠da!")

            # --- Exibi√ß√£o dos Resultados e Visualiza√ß√µes ---
            if 'df_analyzed' in st.session_state and st.session_state.get('text_column') == text_column:
                df_analyzed = st.session_state['df_analyzed']

                st.subheader("Resultados da An√°lise de Sentimentos")
                st.dataframe(df_analyzed[[text_column, 'Sentimento_Label', 'Sentimento_Score']])

                st.markdown("---")
                st.header("üìä Visualiza√ß√µes")

                col1, col2 = st.columns(2)

                with col1:
                    # 1. Gr√°fico de Distribui√ß√£o dos Sentimentos
                    st.subheader("Distribui√ß√£o dos Sentimentos")
                    sentiment_counts = df_analyzed['Sentimento_Label'].value_counts().reset_index()
                    sentiment_counts.columns = ['Sentimento', 'Contagem']

                    # Remover 'N/A' e 'Erro' das contagens para o gr√°fico principal se desejar
                    sentiment_counts_filtered = sentiment_counts[~sentiment_counts['Sentimento'].isin(['N/A', 'Erro'])]

                    if not sentiment_counts_filtered.empty:
                        fig_pie = px.pie(sentiment_counts_filtered, names='Sentimento', values='Contagem',
                                         title="Distribui√ß√£o Percentual",
                                         color='Sentimento',
                                         color_discrete_map={'Positivo':'green', 'Negativo':'red', 'Neutro':'grey'})
                        fig_pie.update_traces(textposition='inside', textinfo='percent+label')
                        st.plotly_chart(fig_pie, use_container_width=True)
                    else:
                         st.warning("N√£o h√° dados suficientes para gerar o gr√°fico de distribui√ß√£o (excluindo N/A e Erros).")

                with col2:
                    # Mostrar contagem exata incluindo N/A e Erro
                    st.subheader("Contagem Total por Sentimento")
                    fig_bar_total = px.bar(sentiment_counts, x='Sentimento', y='Contagem',
                                            title="Contagem Absoluta", text_auto=True,
                                             color='Sentimento',
                                             color_discrete_map={'Positivo':'green', 'Negativo':'red', 'Neutro':'grey', 'N/A':'lightblue', 'Erro': 'orange'})
                    st.plotly_chart(fig_bar_total, use_container_width=True)


                # 2. Palavras Mais Frequentes por Sentimento
                st.markdown("---")
                st.subheader("Palavras Mais Frequentes por Sentimento")
                st.markdown("_Excluindo palavras comuns (stop words) e n√∫meros._")

                # Stop words b√°sicas em Portugu√™s (pode ser expandido ou usar NLTK/spaCy se dispon√≠vel)
                # Fonte simples: https://gist.github.com/alopes/5358189
                stop_words_pt = set([
                    'de', 'a', 'o', 'que', 'e', 'do', 'da', 'em', 'um', 'para', '√©', 'com', 'n√£o', 'uma',
                    'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'foi', 'ao', 'ele',
                    'das', 'tem', '√†', 'seu', 'sua', 'ou', 'ser', 'quando', 'muito', 'h√°', 'nos', 'j√°',
                    'est√°', 'eu', 'tamb√©m', 's√≥', 'pelo', 'pela', 'at√©', 'isso', 'ela', 'entre', 'era',
                    'depois', 'sem', 'mesmo', 'aos', 'ter', 'seus', 'quem', 'nas', 'me', 'esse', 'eles',
                    'est√£o', 'voc√™', 'tinha', 'foram', 'essa', 'num', 'nem', 'suas', 'meu', '√†s', 'minha',
                    't√™m', 'numa', 'pelos', 'elas', 'havia', 'seja', 'qual', 'ser√°', 'n√≥s', 'tenho', 'lhe',
                    'deles', 'essas', 'esses', 'pelas', 'este', 'fosse', 'dele', 'tu', 'te', 'voc√™s', 'vos',
                    'lhes', 'meus', 'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso', 'nossa', 'nossos', 'nossas',
                    'dela', 'delas', 'esta', 'estes', 'estas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'isto',
                    'aquilo', 'estou', 'est√°', 'estamos', 'est√£o', 'estive', 'esteve', 'estivemos', 'estiveram',
                    'estava', 'est√°vamos', 'estavam', 'estivera', 'estiv√©ramos', 'esteja', 'estejamos', 'estejam',
                    'estivesse', 'estiv√©ssemos', 'estivessem', 'estiver', 'estivermos', 'estiverem', 'hei', 'h√°',
                    'havemos', 'h√£o', 'houve', 'houvemos', 'houveram', 'houvera', 'houv√©ramos', 'haja', 'hajamos',
                    'hajam', 'houvesse', 'houv√©ssemos', 'houvessem', 'houver', 'houvermos', 'houverem', 'houverei',
                    'houver√°', 'houveremos', 'houver√£o', 'houveria', 'houver√≠amos', 'houveriam', 'sou', 'somos',
                    's√£o', 'era', '√©ramos', 'eram', 'fui', 'foi', 'fomos', 'foram', 'fora', 'f√¥ramos', 'seja',
                    'sejamos', 'sejam', 'fosse', 'f√¥ssemos', 'fossem', 'for', 'formos', 'forem', 'serei', 'ser√°',
                    'seremos', 'ser√£o', 'seria', 'ser√≠amos', 'seriam', 'tenho', 'tem', 'temos', 't√™m', 'tinha',
                    't√≠nhamos', 'tinham', 'tive', 'teve', 'tivemos', 'tiveram', 'tivera', 'tiv√©ramos', 'tenha',
                    'tenhamos', 'tenham', 'tivesse', 'tiv√©ssemos', 'tivessem', 'tiver', 'tivermos', 'tiverem',
                    'terei', 'ter√°', 'teremos', 'ter√£o', 'teria', 'ter√≠amos', 'teriam', 'pra', 'pro', 't√°', 'n√©',
                    'a√≠', 'l√°', 'c√°', 'etc', 'sobre', 'muita', 'muitos', 'coisa', 'coisas', 'pode', 'onde'
                ])


                sentiments_to_plot = df_analyzed['Sentimento_Label'].unique()
                sentiments_to_plot = [s for s in sentiments_to_plot if s not in ['N/A', 'Erro']] # Exclui N/A e Erro

                if not sentiments_to_plot:
                    st.warning("N√£o h√° categorias de sentimento v√°lidas para exibir contagem de palavras.")
                else:
                    all_word_counts_df = pd.DataFrame()
                    n_top = st.slider("N√∫mero de palavras a exibir por sentimento:", 5, 50, 15)

                    for sentiment in sentiments_to_plot:
                        sentiment_texts = df_analyzed[df_analyzed['Sentimento_Label'] == sentiment][text_column]
                        df_word_counts = get_word_counts(sentiment_texts, sentiment, stop_words_pt, n_top_words=n_top)
                        if not df_word_counts.empty:
                             all_word_counts_df = pd.concat([all_word_counts_df, df_word_counts], ignore_index=True)

                    if not all_word_counts_df.empty:
                         # Usar facet_col para criar um gr√°fico por sentimento
                         fig_words = px.bar(all_word_counts_df, x='Frequ√™ncia', y='Palavra', color='Sentimento',
                                            facet_col='Sentimento', facet_col_wrap=3, # Ajuste o wrap conforme necess√°rio
                                            title=f'Top {n_top} Palavras Mais Frequentes por Sentimento',
                                            labels={'Palavra': '', 'Frequ√™ncia': 'Contagem'},
                                            height=250*len(sentiments_to_plot), # Ajusta altura dinamicamente
                                            color_discrete_map={'Positivo':'green', 'Negativo':'red', 'Neutro':'grey'})
                         fig_words.update_yaxes(matches=None, showticklabels=True) # Garante que os eixos Y sejam independentes
                         fig_words.update_layout(yaxis={'categoryorder':'total ascending'}) # Ordena palavras pela frequ√™ncia
                         st.plotly_chart(fig_words, use_container_width=True)
                    else:
                         st.info("N√£o foram encontradas palavras frequentes para exibir (ap√≥s remover stop words e palavras curtas).")


                # --- Exporta√ß√£o ---
                st.markdown("---")
                st.header("üì• Exportar Resultados")

                col_exp1, col_exp2 = st.columns(2)

                with col_exp1:
                     csv_data = df_analyzed.to_csv(index=False).encode('utf-8')
                     st.download_button(
                         label="Baixar Resultados em CSV",
                         data=csv_data,
                         file_name=f"analise_sentimento_{uploaded_file.name.split('.')[0]}.csv",
                         mime='text/csv',
                     )

                with col_exp2:
                     excel_data = to_excel(df_analyzed)
                     st.download_button(
                         label="Baixar Resultados em Excel (.xlsx)",
                         data=excel_data,
                         file_name=f"analise_sentimento_{uploaded_file.name.split('.')[0]}.xlsx",
                         mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
                     )


        elif uploaded_file and not text_column: # Se um arquivo foi carregado mas nenhuma coluna selecionada
            st.sidebar.warning("Por favor, selecione a coluna que cont√©m o texto.")

elif not uploaded_file:
    st.info("Aguardando o upload de um arquivo .csv ou .xlsx na barra lateral.")